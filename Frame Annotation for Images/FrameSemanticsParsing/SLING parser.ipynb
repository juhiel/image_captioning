{"cells":[{"cell_type":"markdown","id":"2eb57e8a-da43-4b52-8034-1d2db325118d","metadata":{"id":"2eb57e8a-da43-4b52-8034-1d2db325118d"},"source":["# SLING Parser\n","\n","## IDEA:\n","SLING is a surprisingly robust frame semantics parser, able to extract frames from complicated sentences with many layers of nested predicates.\n","\n","However, the interal organization of SLING-related objects remain somewhat unclear, due to relatively little documentation available.\n","\n","Worse yet, the author has moved on from the \"SEMPAR\" model which we used for this project, in favor of another model, the \"CASPAR\" model.\n","\n","In the implementation of the \"CASPAR\" model, the author decided to drop support for PropBank framesets, which are critical to our project.\n","\n","With the code below, much of which we wrote, we were able to adapt the output of SLING to a format suitable for our project."]},{"cell_type":"code","execution_count":null,"id":"a50949e9-e568-4dd2-8cfd-30681f022a02","metadata":{"id":"a50949e9-e568-4dd2-8cfd-30681f022a02"},"outputs":[],"source":["##### IMPORT STATEMENTS #####\n","\n","from collections import OrderedDict\n","from collections import defaultdict\n","import sling\n","import re\n","import json\n","\n","##### SLING PARSER #####\n","\n","# We will use the older SEMPAR model\n","parser = sling.Parser(\"sempar.flow\")\n","\n","\n","##### HELPER FUNCTIONS #####\n","\n","# We will also use code found online, that converts a string with appropriate indentations to a nested list\n","# Reference: https://stackoverflow.com/questions/31551395/tab-formatted-nested-string-to-nested-list-python\n","\n","#==== START OF REFERENCED MATERIAL ====#\n","\n","def parse(data):\n","\n","  currentTab = 0\n","  currentList = []\n","  result = [currentList]\n","\n","  i = 0\n","  tabCount = 0\n","\n","  for line in data.splitlines():\n","\n","    tabCount = len(line)-len(line.lstrip())\n","\n","    line = line.strip().rstrip(' :')\n","\n","    if tabCount == currentTab:\n","        currentList.append(line)\n","\n","    elif tabCount > currentTab:\n","        newList = [line]\n","        currentList.append(newList)\n","        currentList = newList\n","\n","    elif tabCount == 0:\n","        currentList = [line]\n","        result.append(currentList)\n","\n","    elif tabCount == 1:\n","        currentList = [line]\n","        result[-1].append(currentList)\n","\n","    currentTab = tabCount\n","\n","    tabCount = tabCount + 1\n","    i = i + 1\n","\n","  return result\n","  \n","#==== END OF REFERENCED MATERIAL ====#\n","\n","# This is another helper function for parsing verbs in a list\n","# to a nested dictionary structure that we will use\n","\n","def parseverb(li):\n","    \n","    mydict = {}\n","    \n","    for i in range(len(li)):\n","        if i==0:\n","            mydict[\"__verb__\"] = li[i]\n","            \n","        else:\n","            if isinstance(li[i], str):\n","                arg, word = li[i].split(\" \")\n","                \n","                mydict[arg] = word\n","                \n","            elif isinstance(li[i], list):\n","                mydict[\"other verbs\"] = parseverb(li[i])\n","    \n","    return mydict\n","\n","##### TEXT_TO_FRAMES FUNCTION #####\n","\n","# This function, using SLING, takes caption text as an input,\n","# and outputs frame data in a format convinient for our project\n","\n","def text_to_frames(text):\n","    doc = parser.parse(text)\n","    mystr = doc.frame.data(pretty=True)\n","    \n","    index = mystr.find(\"]\")\n","    firsthalf = mystr[:index]\n","    secondhalf = mystr[index+2:]\n","    \n","    #print(firsthalf)\n","    \n","    # Find the largest ref number in the first half\n","    hashtags = re.findall(\"=#[0-9]*\", firsthalf)\n","    \n","    # remove \"=#\" and find max\n","    li = []\n","\n","    for item in hashtags:\n","        li.append(int(item[2:]))\n","        \n","    maxval = max(li)\n","    #print(maxval)\n","    \n","    # Create tok to ref dictionary\n","    from collections import defaultdict\n","\n","    index_to_tok = {}\n","    ref_to_index = {}\n","\n","    i = 2 # First token is ref number 2\n","\n","    for tok in doc.tokens:\n","        ref_to_index[i] = i-2\n","        index_to_tok[i-2] = tok.text\n","        i += 1\n","        \n","    # print(repr(secondhalf))\n","    \n","    mentions = []\n","    \n","    li = []\n","    \n","    ### Curly braces matching ###\n","    matchingmode = False # Engage in parentheses matching, when true\n","    stack = []\n","\n","    startindex = 0\n","\n","    for i in range(len(secondhalf)):\n","        c = secondhalf[i]\n","        \n","        # Engage in matching mode\n","        if (not matchingmode and c==\"{\"):\n","            stack.append(\"{\")\n","            matchingmode = True\n","            startindex = i\n","            \n","        # Disengage from matching mode\n","        elif (matchingmode and c==\"}\" and len(stack)==1):\n","            li.append(secondhalf[startindex:i+1])\n","            stack.pop()\n","            matchingmode = False\n","            \n","        elif (matchingmode and c==\"}\"):\n","            stack.pop()\n","            \n","        elif (matchingmode and c==\"{\"):\n","            stack.append(\"{\")\n","    \n","    text_by_index = text.split(\" \")\n","\n","    # Use regex to format SLING's output\n","    numbers1 = re.findall(\"{=#[0-9]* \\n    :/s/phrase\\n    /s/phrase/begin: [0-9]*\", secondhalf)\n","    numbers2 = re.findall(\"/s/phrase/evokes: [{]?[=]?#[0-9]*\", secondhalf)\n","\n","    for i in range(len(numbers1)):\n","        if numbers1[i][-3]==\":\":\n","            numbers1[i] = numbers1[i][:-2] + \" \" + numbers1[i][-2:]\n","\n","    li1 = []\n","    li2 = []\n","            \n","    for item in numbers1:\n","        li1.append(item[-3:])\n","        \n","    for item in numbers2:\n","        i = item.index(\"#\")\n","        li2.append(item[i+1:])\n","        \n","    #print(li1)\n","\n","    #print(li2)\n","    \n","\n","    mapping = {}\n","\n","    for i in range(len(li1)):\n","        mapping[li2[i]] = text_by_index[int(li1[i])]\n","        \n","    #print(mapping)\n","    \n","    for num in mapping:\n","        for i in range(len(li)):\n","            li[i] = li[i].replace(num+\" \\n\", mapping[num]+\" \\n\")\n","            li[i] = li[i].replace(num+\"\\n\", mapping[num]+\"\\n\")\n","    \n","    predli = []\n","\n","    for item in li:\n","        if \"/pb/arg\" in item:\n","            predli.append(item)\n","            \n","    # More string formatting\n","            \n","    for i in range(len(predli)):\n","        \n","        predli[i] = predli[i].replace(\"/s/phrase\", \"\")\n","        predli[i] = predli[i].replace(\"/pb/\", \"\")\n","        predli[i] = predli[i].replace(\"{\", \"\")\n","        predli[i] = predli[i].replace(\"}\", \"\")\n","        predli[i] = predli[i].replace(\":\", \"\")\n","        predli[i] = predli[i].replace(\"=#\", \"\")\n","        predli[i] = predli[i].replace(\"#\", \"\")\n","        \n","        predli[i] = re.sub(\"[ ]*[0-9]*[ ]*\\n[ ]*\\n[ ]*/begin[ ]*[0-9]*\\n[ ]*/evokes[ ]*[a-z]*[ ]*\", \"\", predli[i])\n","        \n","        \n","    newpredli = []\n","        \n","    for pred in predli:\n","        \n","        #print(\"===\")\n","        #print((pred))\n","       \n","        newpredli.append(pred.split(\"\\n\"))\n","        \n","    for newpred in newpredli:\n","        for i in range(len(newpred)):\n","            newpred[i] = newpred[i].replace(\"  \", \"==>\")\n","            newpred[i] = newpred[i][9:]\n","                \n","    for newpred in newpredli:\n","        for i in range(len(newpred)):\n","            for n in range(21):\n","                if newpred[i]==\"==>\"*n:\n","                    newpred[i] = \"REMOVETHIS\"\n","                if \"/saft/\" in newpred[i] or \"/s/\" in newpred[i]:\n","                    newpred[i] = \"REMOVETHIS\"\n","                    \n","\n","                    \n","    for newpred in newpredli:\n","        while \"REMOVETHIS\" in newpred:\n","            newpred.remove(\"REMOVETHIS\")\n","            \n","    for newpred in newpredli:\n","        for i in range(len(newpred)-1):\n","            line1 = newpred[i]\n","            line2 = newpred[i+1]\n","                \n","    for newpred in newpredli:\n","        while \"REMOVETHIS\" in newpred:\n","            newpred.remove(\"REMOVETHIS\")\n","            \n","    #for newpred in newpredli:\n","        #for line in newpred:\n","            #print(line)\n","    \n","    for newpred in newpredli:\n","        for i in range(len(newpred)):\n","            newpred[i] = newpred[i].replace(\"==>\", \"\\t\")\n","            \n","    longstrli = []\n","\n","    for newpred in newpredli:\n","        longstrli.append(\"\\n\".join(newpred))\n","        \n","    nestli = []\n","\n","    for longstr in longstrli:\n","        nestli.append(parse(longstr))\n","        \n","    vdictli = []\n","    jsonli = []\n","\n","    for nest in nestli:\n","        for p in nest:\n","            vdictli.append(parseverb(p))\n","\n","    for vdict in vdictli:\n","        json_object = json.dumps(vdict, indent = 4, sort_keys=True)\n","        jsonli.append(json_object)\n","            \n","    return jsonli # Output is a list of JSON objects, one for each top-level predicate in a caption"]},{"cell_type":"code","execution_count":null,"id":"77bc52a1-b70e-4f29-9728-9973f3b375fb","metadata":{"id":"77bc52a1-b70e-4f29-9728-9973f3b375fb"},"outputs":[],"source":["# This function allows for the conversion of the JSON objects to tuples\n","# that can be easily used further down in the pipeline\n","def json_to_tuples(js):\n","    lines = js.split(\"\\n\")\n","    \n","    tups = []\n","    \n","    lastverb = \"\"\n","    \n","    for line in lines:\n","        \n","        \n","        if '__verb__' in line:\n","            lastverb = line.split('\"')[-2]\n","        \n","        elif '\"arg' in line:\n","            split = line.split('\"')\n","            tups.append((split[-2], split[1], lastverb))\n","            \n","    return tups"]},{"cell_type":"code","execution_count":null,"id":"09c4ea95-1f25-4bf0-8d47-d2a7a5d5c351","metadata":{"id":"09c4ea95-1f25-4bf0-8d47-d2a7a5d5c351","outputId":"ea6e0d35-cfd8-401c-95d3-1a49362fe036"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","    \"__verb__\": \"close-01\", \n","    \"arg0\": \"woman\", \n","    \"arg1\": \"text\"\n","}\n","[('woman', 'arg0', 'close-01'), ('text', 'arg1', 'close-01')]\n"]}],"source":["# Example of the text_to_frames() function running\n","\n","jsonli = text_to_frames(\"a woman closing a text that a laptop\")\n","for js in jsonli:\n","    print(js)\n","    print(json_to_tuples(js))\n","    "]},{"cell_type":"code","execution_count":null,"id":"5f85df6b-71fb-41ec-8925-4126b8e0de6d","metadata":{"id":"5f85df6b-71fb-41ec-8925-4126b8e0de6d"},"outputs":[],"source":["# Code for running the defined text_to_frames() function on the output from\n","# the previous segment of the pipeline, and writing the output of our function\n","# to a file so that it can be used further down the pipeline\n","\n","f = open(\"capOutput.txt\", \"r\")\n","\n","capli = []\n","\n","while(True):\n","\n","    line = f.readline()\n","    \n","    if not line:\n","        break\n","    \n","    \n","    line = line.replace(\",\", \"\")\n","    line = line.replace(\"'\", \"\")\n","    line = line.replace(\". <end>\\r\\n\", \"\")\n","    line = line.replace(\". <end> \\r\\n\", \"\")\n","    line = line.replace(\". <end>\", \"\")\n","    line = re.split(':.', line)\n","    \n","    capli.append(line[1])\n","    \n","framesli = []\n","    \n","for cap in capli:\n","    \n","    frames = []\n","    \n","    jsonli = text_to_frames(cap)\n","    \n","    for js in jsonli:\n","        frames.append(json_to_tuples(js))\n","    \n","    framesli.append(frames)\n","    \n","overalldict = {}\n","    \n","for i in range(len(framesli)):\n","    \n","    idict = defaultdict(list)\n","    \n","    for subframe in framesli[i]:\n","        for tup in subframe:\n","            idict[tup[0]].append((tup[1], tup[2]))\n","            \n","    overalldict[i] = dict(idict)\n","\n","with open('output.json', 'w') as f:\n","    json.dump(overalldict, f)\n","            \n","    "]}],"metadata":{"environment":{"kernel":"conda-env-python27-py","name":"common-cpu.m91","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cpu:m91"},"kernelspec":{"display_name":"Python [conda env:python27]","language":"python","name":"conda-env-python27-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.15"},"colab":{"name":"SLING parser.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}